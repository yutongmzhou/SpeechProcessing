# -*- coding: utf-8 -*-
"""classification.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1tNiMRR38tu4C3SFVCusNPBVVBJuRyDib
"""

import pandas as pd
import tensorflow as tf
from keras import activations
from tensorflow.keras import Input
from tensorflow.keras import layers,Model

from google.colab import drive
drive.mount('/content/drive/')

file_path = #fill in with filepath
text_train_features = file_path + 'text_features_train.csv'
text_valid_features = file_path + 'text_features_valid.csv'
text_test_features = file_path + 'text_features_test.csv'

Y_pred = []
top_10_da_tags = ['sd', 'b', 'sv', 'aa', '%', 'ba', 'qy', 'x', 'ny', 'fc']

def train_and_classify(train_file, epochs_count, val_split, test_file, valid_file, output_filename, da_tag_index):
    from sklearn.metrics import f1_score
    from sklearn.neural_network import MLPClassifier

    df = pd.read_csv(train_file)

    df = df.loc[~df['da_tag'].isin(top_10_da_tags)==False]

    #change the index for below depending on where the da_tag column is
    da_tags = df.iloc[:, da_tag_index]
    features = df.iloc[:, 6:].values.tolist()
    Y_train = []

    counter = 0
    for tag in da_tags:
      counter += 1
      try:
        Y_train.append(top_10_da_tags.index(tag))
      except:
        print(f'Error for {tag} in line {counter}')

    (X_train, Y_train) = (features, Y_train)

    #split training data into train and validation data
    X_train, Y_train, X_val_split, Y_val_split = X_train[:val_split], Y_train[:val_split], X_train[val_split:], Y_train[val_split:]

    df = pd.read_csv(valid_file)
    df = df.loc[~df['da_tag'].isin(top_10_da_tags)==False]
    da_tags = df.iloc[:, da_tag_index]
    features = df.iloc[:, 6:].values.tolist()
    Y_val = []

    for tag in da_tags:
      Y_val.append(top_10_da_tags.index(tag))

    #we use the validation data to evaluate performance
    (X_val, Y_val) = (features, Y_val)

    #A basic neural network using Tensorflow. Use this or any alternative, or the MLPClassifier
    model = tf.keras.Sequential()
    model.add(layers.Flatten())
    model.add(layers.Dense(256,activation=activations.softmax))
    model.add(layers.Dense(128,activation=activations.softmax))
    model.add(layers.Dense(32, activation=activations.softmax))
    model.add(layers.Dense(16, activation=activations.softmax))
    model.compile(optimizer="Adam", loss="sparse_categorical_crossentropy",metrics=['accuracy'])
    history = model.fit(X_train, Y_train, epochs=epochs_count, validation_data=(X_val_split, Y_val_split))
    model.evaluate(X_val,Y_val)

    #classifier = MLPClassifier(alpha=1.9,max_iter=700)
    #alternative classifier

    import numpy as np

    y_pred = model.predict(X_val, verbose=0)
    y_pred =  [top_10_da_tags[np.argmax(predictions)] for predictions in y_pred]
    y_true = [top_10_da_tags[np.argmax(predictions)] for predictions in Y_val]

    print("F1 score:")
    print(f1_score(y_true, y_pred, average='macro'))

    df = pd.read_csv(test_file)
    X_test = df.iloc[:, 6:].values.tolist()

    Y_test = model.predict(X_test, verbose=0)

    df['da_tag'] = [top_10_da_tags[np.argmax(predictions)] for predictions in Y_test]
    df.to_csv(file_path + output_filename, index=False)

    return y_pred, y_true

epochs_count = 30
text_y_pred, text_y_true = train_and_classify(text_train_features, epochs_count, 60000, text_test_features, text_valid_features, 'test_yz4429_text.csv', 3)

speech_train_features = file_path + 'speech_features_train.csv'
speech_valid_features = file_path + 'speech_features_valid.csv'
speech_test_features = file_path + 'speech_features_test.csv'

speech_y_pred, speech_y_true = train_and_classify(speech_train_features, epochs_count, 5000, speech_test_features, speech_valid_features, 'test_yz4429_speech.csv', 2)

multi_train_features = file_path + 'multi_features_train.csv'
multi_valid_features = file_path + 'multi_features_valid.csv'
multi_test_features = file_path + 'multi_features_test.csv'

multi_y_pred, multi_y_true = train_and_classify(multi_train_features, epochs_count, 5000, multi_test_features, multi_valid_features, 'test_yz4429_multi.csv', 2)

#Confusion matrix plotting code sourced from https://github.com/theharshy/dialogue-act-recognition/blob/master/classification_text.ipynb

import matplotlib.pyplot as plt
from sklearn.metrics import confusion_matrix
import numpy as np

def plot_confusion_matrix(y_true, y_pred, classes,cmap=plt.cm.Blues):
    """Returns a confusion matrix."""
    title = 'Confusion Matrix'

    # Compute confusion matrix
    cm = confusion_matrix(y_true, y_pred)

    fig, ax = plt.subplots()
    im = ax.imshow(cm, interpolation='nearest', cmap=cmap)
    ax.figure.colorbar(im, ax=ax)
    # We want to show all ticks...
    ax.set( xticks=np.arange(cm.shape[1]),
            yticks=np.arange(cm.shape[0]),
            # ... and label them with the respective list entries
            xticklabels=classes, yticklabels=classes,
            title=title,
            ylabel='True label',
            xlabel='Predicted label')

    # Rotate the tick labels and set their alignment.
    plt.setp(ax.get_xticklabels(), rotation=45, ha="right",
            rotation_mode="anchor")

    # Loop over data dimensions and create text annotations.
    fmt = 'd'
    thresh = cm.max() / 2.
    for i in range(cm.shape[0]):
        for j in range(cm.shape[1]):
            ax.text(j, i, format(cm[i, j], fmt),
                    ha="center", va="center",
                    color="white" if cm[i, j] > thresh else "black")
    fig.tight_layout()
    return ax

confusion_matrix(text_y_true, text_y_pred)